#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø –° –ú–£–õ–¨–¢–ò–ö–õ–ê–°–°–û–í–û–ô –î–ï–¢–ï–ö–¶–ò–ï–ô - REFACTORED

–ü–∞–Ω–æ—Ä–∞–º–∞ —Å –¥–≤—É–º—è —Ä–µ–∂–∏–º–∞–º–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∑–∞–ø–∏—Å—å—é:
- panorama: –ø–æ–ª–Ω–∞—è –ø–∞–Ω–æ—Ä–∞–º–∞ —Å –æ—Ç—Ä–∏—Å–æ–≤–∫–æ–π bbox —á–µ—Ä–µ–∑ nvdsosd
- virtualcam: –≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –∫–∞–º–µ—Ä–∞, —Å–ª–µ–¥—è—â–∞—è –∑–∞ –º—è—á–æ–º (—Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∑–∞–ø–∏—Å–∏)
- stream: —Å—Ç—Ä–∏–º–∏–Ω–≥ –Ω–∞ stream
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: —Ñ–∞–π–ª—ã –∏–ª–∏ –∫–∞–º–µ—Ä—ã MIPI CSI

=== –ú–£–õ–¨–¢–ò–ö–õ–ê–°–°–û–í–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò ===
1. –î–µ—Ç–µ–∫—Ü–∏—è 5 –∫–ª–∞—Å—Å–æ–≤: ball, player, staff, side_referee, main_referee
2. –•—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –∏–≥—Ä–æ–∫–æ–≤ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —Ü–µ–Ω—Ç—Ä–∞ –º–∞—Å—Å
3. Fallback: –ø—Ä–∏ –ø–æ—Ç–µ—Ä–µ –º—è—á–∞ –∫–∞–º–µ—Ä–∞ —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∏–≥—Ä–æ–∫–∞—Ö
4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ panorama —Ä–µ–∂–∏–º–µ:
   - –ú—è—á: –ö–†–ê–°–ù–´–ô —Ü–≤–µ—Ç (border=3)
   - –ò–≥—Ä–æ–∫–∏: –ó–ï–õ–Å–ù–´–ô —Ü–≤–µ—Ç (border=2)
   - –õ–∏–º–∏—Ç –æ—Ç—Ä–∏—Å–æ–≤–∫–∏: 16 –æ–±—ä–µ–∫—Ç–æ–≤ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ nvdsosd –Ω–∞ Jetson)
   - –¢–∞–π–ª—ã –û–¢–ö–õ–Æ–ß–ï–ù–´ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Å–ª–æ—Ç–æ–≤

–ü–†–ò–û–†–ò–¢–ï–¢ –û–¢–†–ò–°–û–í–ö–ò: –º—è—á ‚Üí –∏–≥—Ä–æ–∫–∏ (–ø–µ—Ä—Å–æ–Ω–∞–ª –∏ —Å—É–¥—å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã)

=== REFACTORED VERSION ===
This version uses modular architecture with delegation:
- utils: FieldMaskBinary, CSV logging, NMS
- core: HistoryManager (replaces BallDetectionHistory), PlayersHistory
- processing: TensorProcessor, AnalysisProbeHandler
- rendering: VirtualCameraProbeHandler, DisplayProbeHandler
- pipeline: ConfigBuilder, PipelineBuilder, PlaybackPipelineBuilder, BufferManager
"""

import sys
import os
import gi
gi.require_version('Gst', '1.0')
from gi.repository import Gst, GLib
import pyds
import numpy as np
import ctypes
from typing import List, Dict, Tuple, Optional
from collections import deque, defaultdict
from dataclasses import dataclass
import logging
import time
import math
import threading
import csv
import cv2

# ============================================================
# Import all extracted modules
# ============================================================
# Utilities
from utils import FieldMaskBinary, save_detection_to_csv, apply_nms

# Core detection and history management
from core import HistoryManager, PlayersHistory

# Processing (YOLO inference and analysis)
from processing import TensorProcessor, AnalysisProbeHandler

# Rendering (virtual camera and display)
from rendering import VirtualCameraProbeHandler, DisplayProbeHandler

# Pipeline builders and buffer management
from pipeline import ConfigBuilder, PipelineBuilder, PlaybackPipelineBuilder, BufferManager

# ============================================================
# Logging configuration
# ============================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("panorama-virtualcam")

# ============================================================
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GStreamer
# ============================================================
# –ü–ª–∞–≥–∏–Ω—ã —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –≤ ~/.local/share/gstreamer-1.0/plugins/
# GStreamer –Ω–∞–π–¥—ë—Ç –∏—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
Gst.init(None)


# ============================================================
# –ö–û–ù–°–¢–ê–ù–¢–´ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –ü–ê–ù–û–†–ê–ú–´
# ============================================================
# –†–∞–∑–º–µ—Ä—ã –ø–∞–Ω–æ—Ä–∞–º—ã (–æ–±–Ω–æ–≤–ª–µ–Ω–æ —Å 1632 –Ω–∞ 1800 –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ FOV –¥–æ 75¬∞)
PANORAMA_WIDTH = 5700
PANORAMA_HEIGHT = 1900

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–∞–π–ª–æ–≤ –¥–ª—è nvtilebatcher
TILE_WIDTH = 1024
TILE_HEIGHT = 1024
TILES_COUNT = 6

# –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π –æ—Ç—Å—Ç—É–ø —Ç–∞–π–ª–æ–≤: —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Å–∫–∏ –ø–æ–ª—è
# –õ–æ–≥–∏–∫–∞: –Ω–∞—Ö–æ–¥–∏–º —Ü–µ–Ω—Ç—Ä –ø–æ–ª—è (field_top + field_bottom)/2, –≤—ã—á–∏—Ç–∞–µ–º –ø–æ–ª–æ–≤–∏–Ω—É —Ç–∞–π–ª–∞ (512)
# Field bounds: top=438, bottom=1454 ‚Üí center=946 ‚Üí offset = 946 - 512 = 434
TILE_OFFSET_Y = 434  # –†–∞—Å—Å—á–∏—Ç–∞–Ω–æ –∏–∑ field_mask.png (–±—ã–ª–æ: 304 —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–µ)
TILE_OFFSET_X = 192  # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π margin –¥–ª—è 6 —Ç–∞–π–ª–æ–≤ (6√ó1024=6144, margin=(6528-6144)/2)

# –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–∞–π–ª–æ–≤ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è)
TILE_POSITIONS = [
    (TILE_OFFSET_X,                   TILE_OFFSET_Y, TILE_WIDTH, TILE_HEIGHT),  # Tile 0
    (TILE_OFFSET_X + TILE_WIDTH,      TILE_OFFSET_Y, TILE_WIDTH, TILE_HEIGHT),  # Tile 1
    (TILE_OFFSET_X + TILE_WIDTH * 2,  TILE_OFFSET_Y, TILE_WIDTH, TILE_HEIGHT),  # Tile 2
    (TILE_OFFSET_X + TILE_WIDTH * 3,  TILE_OFFSET_Y, TILE_WIDTH, TILE_HEIGHT),  # Tile 3
    (TILE_OFFSET_X + TILE_WIDTH * 4,  TILE_OFFSET_Y, TILE_WIDTH, TILE_HEIGHT),  # Tile 4
    (TILE_OFFSET_X + TILE_WIDTH * 5,  TILE_OFFSET_Y, TILE_WIDTH, TILE_HEIGHT),  # Tile 5
]


# ============================================================
# MAIN ORCHESTRATOR CLASS (REFACTORED)
# ============================================================

class PanoramaWithVirtualCamera:
    """
    –ü–∞–Ω–æ—Ä–∞–º–∞ —Å –¥–≤—É–º—è —Ä–µ–∂–∏–º–∞–º–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∑–∞–ø–∏—Å—å—é –∏ –µ–¥–∏–Ω–æ–π –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–µ–π.

    REFACTORED VERSION:
    This class now focuses on orchestration and delegates functionality to specialized handlers:

    Delegation Map:
    ---------------
    ConfigBuilder: Inference config generation
    PipelineBuilder: Analysis pipeline construction
    PlaybackPipelineBuilder: Playback pipeline construction
    BufferManager: Frame/audio buffering and playback management
    AnalysisProbeHandler: YOLO tensor processing and detection
    VirtualCameraProbeHandler: Virtual camera control and ball tracking
    DisplayProbeHandler: Panorama rendering with bboxes
    HistoryManager: Ball detection history (replaces BallDetectionHistory)
    PlayersHistory: Player detection history for fallback
    TensorProcessor: YOLO output tensor processing
    FieldMaskBinary: Field mask validation
    """

    def __init__(self,
                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –≤–∏–¥–µ–æ
                source_type: str = "files",
                video1: str = "left1.mp4",
                video2: str = "right1.mp4",
                config_path: str = None,
                buffer_duration: float = 5.0,
                enable_display: bool = True,
                display_mode: str = "panorama",  # "panorama", "virtualcam", "stream", "record"
                enable_analysis: bool = True,
                analysis_skip_interval: int = 5,
                confidence_threshold: float = 0.35,
                auto_zoom: bool = True,
                stream_key: str = None,
                stream_url: str = None,
                output_file: str = None,
                bitrate: int = 6000000):

        # Store configuration
        self.source_type = source_type
        self.video1 = video1
        self.video2 = video2
        self.buffer_duration = float(buffer_duration)
        self.enable_display = enable_display
        self.display_mode = display_mode
        self.enable_analysis = enable_analysis
        self.confidence_threshold = confidence_threshold
        self.auto_zoom = auto_zoom
        self.stream_key = stream_key
        self.stream_url = stream_url
        self.output_file = output_file
        self.bitrate = bitrate

        # Panorama dimensions (global constants)
        self.panorama_width = PANORAMA_WIDTH
        self.panorama_height = PANORAMA_HEIGHT

        # ROI configuration - use pre-calculated tile positions
        self.roi_configs = TILE_POSITIONS

        # ============================================================
        # DELEGATED: Field mask validation ‚Üí FieldMaskBinary (utils)
        # ============================================================
        self.field_mask = FieldMaskBinary(
            mask_path='field_mask.png',
            panorama_width=self.panorama_width,
            panorama_height=self.panorama_height
        )

        # ============================================================
        # DELEGATED: Ball detection history ‚Üí HistoryManager (core)
        # Replaces: BallDetectionHistory
        # ============================================================
        self.history = HistoryManager(history_duration=10.0, cleanup_interval=1000)

        # ============================================================
        # DELEGATED: Players history ‚Üí PlayersHistory (core)
        # ============================================================
        self.players_history = PlayersHistory(history_duration=10.0)

        # ============================================================
        # DELEGATED: Tensor processing ‚Üí TensorProcessor (processing)
        # ============================================================
        self.tensor_processor = TensorProcessor(conf_thresh=confidence_threshold)

        # Adaptive filter state (kept in main class for now)
        self.last_ball_position = None
        self.frames_without_reliable_detection = 0

        # All detections storage for rendering (synced by timestamp)
        self.all_detections_history = {}  # {timestamp: {'ball': [...], 'player': [...], ...}}

        # EMA smoothing for player center of mass
        self.players_center_mass_smoothed = None  # (x, y) - smoothed position
        self.players_center_mass_alpha = 0.18  # Smoothing coefficient

        # Raw position buffer for detecting back-and-forth patterns
        self.players_center_mass_history = []  # [(x, y), ...] last 10 raw positions
        self.players_center_mass_history_max = 10

        # Virtual camera element reference
        self.vcam = None

        # Statistics
        self.display_frame_count = 0
        self.analysis_frame_count = 0
        self.analysis_skip_counter = 0
        self.analysis_skip_interval = max(1, int(analysis_skip_interval))
        self.analysis_actual_frame = 0
        self.detection_count = 0
        self.start_time = None
        self.current_fps = 0.0

        # Timestamp for backward interpolation
        self.current_display_timestamp = 0.0  # Current playback timestamp

        # ============================================================
        # DELEGATED: Buffer management ‚Üí BufferManager (pipeline)
        # ============================================================
        self.framerate = 30
        self.buffer_manager = BufferManager(
            buffer_duration=buffer_duration,
            framerate=self.framerate
        )

        # Keep references for compatibility (delegated to BufferManager)
        self.appsink = None
        self.appsrc = None
        self.audio_appsrc = None
        self.audio_appsink_analysis = None  # Audio appsink from analysis pipeline
        self.audio_device = None  # Audio device (e.g., "pulse")
        self.playback_pipeline = None

        # Pipelines
        self.pipeline = None
        self.loop = GLib.MainLoop()

        # ============================================================
        # DELEGATED: Config generation ‚Üí ConfigBuilder (pipeline)
        # ============================================================
        self.config_builder = ConfigBuilder()
        self.config_path = config_path or self.config_builder.create_inference_config()

        # Speed zoom settings
        self.speed_zoom_enabled = True
        self.speed_history = deque(maxlen=5)
        self.last_speed_calc_time = 0
        self.last_speed_calc_pos = None
        self.current_smooth_speed = 0.0
        self.speed_zoom_factor = 1.6

        # Ball radius interpolation for smooth zoom
        self.smooth_ball_radius = 20.0
        self.radius_smooth_factor = 0.3

        # Ball loss behavior parameters
        self.ball_lost = False
        self.ball_lost_frames = 0
        self.last_known_position = None
        self.lost_ball_fov_rate = 2.0
        self.max_search_fov = 90.0
        self.ball_recovery_frames = 6

        # Speed thresholds (pixels/sec)
        self.speed_low_threshold = 300.0
        self.speed_high_threshold = 1200.0
        self.speed_zoom_max_factor = 3.0
        self.speed_smoothing = 0.3

        # ============================================================
        # DELEGATED: Display rendering ‚Üí DisplayProbeHandler (rendering)
        # ============================================================
        self.display_probe_handler = DisplayProbeHandler(
            ball_history=self.history,
            players_history=self.players_history,
            all_detections_history=self.all_detections_history,
            display_mode=self.display_mode
        )

        # ============================================================
        # DELEGATED: Virtual camera ‚Üí VirtualCameraProbeHandler (rendering)
        # Will be initialized after pipeline creation when vcam element is available
        # ============================================================
        self.vcam_probe_handler = None

        # ============================================================
        # DELEGATED: Analysis probe ‚Üí AnalysisProbeHandler (processing)
        # Will be initialized after we have all required references
        # ============================================================
        self.analysis_probe_handler = None

        # Clean up old log files
        for log_file in ['ball_events.tsv', 'ball_raw_future.csv', 'ball_display_used.csv']:
            if os.path.exists(log_file):
                os.remove(log_file)
                logger.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –ª–æ–≥: {log_file}")

    def frame_skip_probe(self, pad, info, u_data):
        """
        Frame skip probe for analysis pipeline.

        KEPT IN MAIN CLASS: Simple frame counting logic for skip interval.
        """
        self.analysis_skip_counter += 1
        if self.analysis_skip_counter % self.analysis_skip_interval != 0:
            return Gst.PadProbeReturn.DROP
        return Gst.PadProbeReturn.OK

    def create_pipeline(self) -> bool:
        """
        Create the main analysis pipeline.

        DELEGATED TO: PipelineBuilder (pipeline module)
        """
        # Initialize pipeline builder (roi_configs removed - handled internally by builder)
        pipeline_builder = PipelineBuilder(
            source_type=self.source_type,
            video1=self.video1,
            video2=self.video2,
            config_path=self.config_path,
            panorama_width=self.panorama_width,
            panorama_height=self.panorama_height,
            buffer_duration=self.buffer_duration,
            framerate=self.framerate
        )

        # Build pipeline - use correct method name
        result = pipeline_builder.create_pipeline()
        if not result:
            return False

        # Extract pipeline and elements
        self.pipeline = result['pipeline']
        self.appsink = result['appsink']

        # Store audio_appsink if available
        self.audio_appsink_analysis = result.get('audio_appsink')
        self.audio_device = result.get('audio_device')

        # ============================================================
        # DELEGATED: Analysis probe ‚Üí AnalysisProbeHandler (processing)
        # ============================================================
        # Now we can initialize the analysis probe handler with all dependencies
        self.analysis_probe_handler = AnalysisProbeHandler(
            ball_history=self.history,
            players_history=self.players_history,
            field_mask=self.field_mask,
            tensor_processor=self.tensor_processor,
            roi_configs=self.roi_configs,
            all_detections_history=self.all_detections_history,
            panorama_width=self.panorama_width,
            panorama_height=self.panorama_height
        )

        # Connect frame skip probe - get element by name
        frame_filter = self.pipeline.get_by_name("frame-filter")
        if frame_filter:
            filter_src_pad = frame_filter.get_static_pad("src")
            if filter_src_pad:
                filter_src_pad.add_probe(Gst.PadProbeType.BUFFER, self.frame_skip_probe, None)
                logger.info("‚úì Frame skip probe connected")

        # Connect analysis probe - get nvinfer by name
        nvinfer = self.pipeline.get_by_name("primary-infer")
        if nvinfer:
            nvinfer_src_pad = nvinfer.get_static_pad("src")
            if nvinfer_src_pad:
                nvinfer_src_pad.add_probe(
                    Gst.PadProbeType.BUFFER,
                    self.analysis_probe_handler.handle_analysis_probe,
                    None
                )
                logger.info("‚úì Analysis probe connected")

        # ============================================================
        # DELEGATED: Buffer sink ‚Üí BufferManager (pipeline)
        # ============================================================
        # Connect appsink callback to buffer manager
        if self.appsink:
            self.appsink.set_property("emit-signals", True)
            self.appsink.connect("new-sample", self.buffer_manager.on_new_sample)
            logger.info("‚úì Video appsink connected to buffer manager")

        logger.info("‚úì Analysis pipeline created successfully")
        return True

    def create_playback_pipeline(self) -> bool:
        """
        Create the playback pipeline for delayed display.

        DELEGATED TO: PlaybackPipelineBuilder (pipeline module)
        """
        # Initialize playback builder (framerate and auto_zoom removed - not in __init__)
        # Pass audio_device and audio_appsink from analysis pipeline
        playback_builder = PlaybackPipelineBuilder(
            display_mode=self.display_mode,
            panorama_width=self.panorama_width,
            panorama_height=self.panorama_height,
            stream_url=self.stream_url,
            stream_key=self.stream_key,
            output_file=self.output_file,
            bitrate=self.bitrate,
            audio_device=self.audio_device,
            audio_appsink=self.audio_appsink_analysis
        )

        # Build pipeline - use correct method name
        result = playback_builder.create_playback_pipeline()
        if not result:
            return False

        # Extract pipeline and elements
        self.playback_pipeline = result['pipeline']
        self.appsrc = result['appsrc']
        self.audio_appsrc = result.get('audio_appsrc')
        self.vcam = result.get('vcam')

        # ============================================================
        # DELEGATED: Virtual camera control ‚Üí VirtualCameraProbeHandler (rendering)
        # ============================================================
        if self.vcam and self.display_mode in ['virtualcam', 'stream', 'record']:
            self.vcam_probe_handler = VirtualCameraProbeHandler(
                ball_history=self.history,
                players_history=self.players_history,
                all_detections_history=self.all_detections_history,
                vcam=self.vcam
            )

            # Connect vcam probe
            vcam_sink_pad = self.vcam.get_static_pad("sink")
            if vcam_sink_pad:
                vcam_sink_pad.add_probe(
                    Gst.PadProbeType.BUFFER,
                    self.vcam_probe_handler.handle_vcam_update_probe,
                    None
                )
                logger.info("‚úì Virtual camera probe connected")

        # ============================================================
        # DELEGATED: Display probe ‚Üí DisplayProbeHandler (rendering)
        # ============================================================
        # Connect display probe for panorama rendering (get osd by name)
        if self.display_mode == 'panorama':
            osd = self.playback_pipeline.get_by_name("nvdsosd")
            if osd:
                osd_sink_pad = osd.get_static_pad("sink")
                if osd_sink_pad:
                    osd_sink_pad.add_probe(
                        Gst.PadProbeType.BUFFER,
                        self.display_probe_handler.handle_playback_draw_probe,
                        None
                    )
                    logger.info("‚úì Display probe connected to nvdsosd")

        # ============================================================
        # DELEGATED: appsrc callbacks ‚Üí BufferManager (pipeline)
        # ============================================================
        if self.appsrc:
            self.appsrc.set_property("emit-signals", True)
            self.appsrc.connect("need-data", self.buffer_manager._on_appsrc_need_data)
            logger.info("‚úì Video appsrc connected to buffer manager")

        if self.audio_appsrc:
            self.audio_appsrc.set_property("emit-signals", True)
            self.audio_appsrc.connect("need-data", self.buffer_manager._on_audio_appsrc_need_data)
            logger.info("‚úì Audio appsrc connected to buffer manager")

        # Store references in buffer manager
        self.buffer_manager.set_elements(
            appsrc=self.appsrc,
            audio_appsrc=self.audio_appsrc,
            playback_pipeline=self.playback_pipeline
        )

        logger.info("‚úì Playback pipeline created successfully")
        return True

    def _on_bus_message(self, bus, message):
        """
        Handle GStreamer bus messages.

        KEPT IN MAIN CLASS: Core orchestration logic for error handling and EOS.
        """
        t = message.type
        if t == Gst.MessageType.ERROR:
            err, debug = message.parse_error()
            logger.error(f"[BUS] ERROR: {err}; debug: {debug}")
            self.stop()
        elif t == Gst.MessageType.EOS:
            logger.info("[BUS] EOS")
            self.stop()
        return True

    def run(self) -> bool:
        """
        Start the application.

        KEPT IN MAIN CLASS: Core orchestration - creates pipelines, starts threads, runs main loop.
        """
        if not self.create_pipeline():
            return False

        if not self.create_playback_pipeline():
            return False

        if self.display_mode == "stream":
            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ stream —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ —Å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –∫–∞–º–µ—Ä–æ–π")
            logger.info(f"üîë –ö–ª—é—á: {self.stream_key[:4]}...{self.stream_key[-4:]}")
            logger.info(f"üì∫ URL: {self.stream_url}")
            logger.info(f"üì∑ –í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –∫–∞–º–µ—Ä–∞ –±—É–¥–µ—Ç —Å–ª–µ–¥–∏—Ç—å –∑–∞ –º—è—á–æ–º")
        else:
            logger.info(f"–ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤ —Ä–µ–∂–∏–º–µ {self.display_mode}‚Ä¶")

        # Connect bus handlers
        main_bus = self.pipeline.get_bus()
        main_bus.add_signal_watch()
        main_bus.connect("message", self._on_bus_message)

        pb_bus = self.playback_pipeline.get_bus()
        pb_bus.add_signal_watch()
        pb_bus.connect("message", self._on_bus_message)

        # Start pipelines
        logger.info(f"–ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤ —Ä–µ–∂–∏–º–µ {self.display_mode}‚Ä¶")
        self.pipeline.set_state(Gst.State.PLAYING)

        self.start_time = time.time()

        # ============================================================
        # DELEGATED: Buffer loop ‚Üí BufferManager (pipeline)
        # ============================================================
        self.buffer_manager.start_buffer_thread()

        try:
            logger.info("–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –∑–∞–ø—É—â–µ–Ω. –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞.")
            self.loop.run()
        except KeyboardInterrupt:
            logger.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).")
        finally:
            self.stop()

        return True

    def stop(self):
        """
        Clean shutdown.

        KEPT IN MAIN CLASS: Core orchestration for cleanup.
        DELEGATED: Buffer thread management ‚Üí BufferManager
        """
        # ============================================================
        # DELEGATED: Stop buffer thread ‚Üí BufferManager (pipeline)
        # ============================================================
        self.buffer_manager.stop_buffer_thread()

        # Send EOS to appsrc if available
        try:
            if self.appsrc:
                self.appsrc.emit("end-of-stream")
        except:
            pass

        # Stop playback pipeline
        try:
            if self.playback_pipeline:
                self.playback_pipeline.set_state(Gst.State.NULL)
        except:
            pass

        # Stop analysis pipeline
        try:
            if self.pipeline:
                self.pipeline.set_state(Gst.State.NULL)
        except:
            pass

        # Stop main loop
        try:
            if self.loop.is_running():
                self.loop.quit()
        except:
            pass

        logger.info(f"[STATS] recv={self.buffer_manager.frames_received}, sent={self.buffer_manager.frames_sent}")
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")


# =========================
# MAIN FUNCTION
# =========================

def main():
    import argparse

    parser = argparse.ArgumentParser(description='–ü–∞–Ω–æ—Ä–∞–º–∞ —Å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –∫–∞–º–µ—Ä–æ–π –∏ –∑–∞–ø–∏—Å—å—é')

    # –í—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    parser.add_argument('--source', choices=['files', 'cameras'], default='files',
                       help='–ò—Å—Ç–æ—á–Ω–∏–∫ –≤–∏–¥–µ–æ: files (–≤–∏–¥–µ–æ—Ñ–∞–π–ª—ã) –∏–ª–∏ cameras (MIPI CSI –∫–∞–º–µ—Ä—ã)')

    # –ò—Å—Ç–æ—á–Ω–∏–∫–∏
    parser.add_argument('--video1', default="left.mp4",
                       help="–õ–µ–≤–æ–µ –≤–∏–¥–µ–æ (–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ ID –∫–∞–º–µ—Ä—ã)")
    parser.add_argument('--video2', default="right.mp4",
                       help="–ü—Ä–∞–≤–æ–µ –≤–∏–¥–µ–æ (–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ ID –∫–∞–º–µ—Ä—ã)")

    parser.add_argument('--config', default=None, help="–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É nvinfer")
    parser.add_argument('--buffer', type=float, default=5.0, help="–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±—É—Ñ–µ—Ä–∞ (—Å–µ–∫)")

    parser.add_argument('--mode', choices=['panorama', 'virtualcam', 'stream', 'record'],
                       default='virtualcam',
                       help='–†–µ–∂–∏–º: panorama=–æ–∫–Ω–æ –ø–∞–Ω–æ—Ä–∞–º—ã, virtualcam=–æ–∫–Ω–æ –∫–∞–º–µ—Ä—ã, stream=—Å—Ç—Ä–∏–º –Ω–∞ YouTube, record=—Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª')

    parser.add_argument('--output', type=str, default=None,
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –∑–∞–ø–∏—Å–∏ (—Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–∞—Ö stream –∏ record)')

    parser.add_argument('--stream-url', default='rtmp://a.rtmp.youtube.com/live2/',
                       help='RTMP URL –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: rtmp://live.twitch.tv/live)')
    parser.add_argument('--stream-key', default='eub1-0rce-quc6-c1xm-d72s',
                       help='–ö–ª—é—á —Å—Ç—Ä–∏–º–∞ stream')
    parser.add_argument('--bitrate', type=int, default=6000000,
                       help='–ë–∏—Ç—Ä–µ–π—Ç –≤–∏–¥–µ–æ –≤ bps (3500000=3.5Mbps –¥–ª—è —Å–ª–∞–±–æ–≥–æ 4G, 4500000=4.5Mbps –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ 4G, 6000000=6Mbps –¥–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ WiFi/4G)')
    parser.add_argument('--skip-interval', type=int, default=15,
                       help='–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä')
    parser.add_argument('--confidence', type=float, default=0.35,
                       help='–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏')
    parser.add_argument('--no-zoom', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–∑—É–º –≤ —Ä–µ–∂–∏–º–µ virtualcam')
    parser.add_argument('--disable-display', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ')
    parser.add_argument('--disable-analysis', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑')

    args = parser.parse_args()

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø–∏—Å–∏
    if args.output:
        # --output —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å —Ä–µ–∂–∏–º–∞–º–∏ stream –∏ record
        if args.mode not in ['stream', 'record']:
            logger.error("–û—à–∏–±–∫–∞: --output —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å —Ä–µ–∂–∏–º–∞–º–∏ 'stream' –∏–ª–∏ 'record'")
            logger.error(f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: {args.mode}")
            return 1

        # –î–ª—è —Ä–µ–∂–∏–º–∞ record –ø–∞—Ä–∞–º–µ—Ç—Ä --output –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
        if args.mode == 'record' and not args.output:
            logger.error("–û—à–∏–±–∫–∞: –¥–ª—è —Ä–µ–∂–∏–º–∞ 'record' –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --output <—Ñ–∞–π–ª>")
            return 1

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∂–∏–º–∞ record –±–µ–∑ --output
    if args.mode == 'record' and not args.output:
        logger.error("–û—à–∏–±–∫–∞: –¥–ª—è —Ä–µ–∂–∏–º–∞ 'record' –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --output <—Ñ–∞–π–ª>")
        return 1

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –±–∏—Ç—Ä–µ–π—Ç–∞ –¥–ª—è —Ä–µ–∂–∏–º–∞ record
    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ù–ï —É–∫–∞–∑–∞–ª --bitrate —è–≤–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º—É–º –¥–ª—è –∑–∞–ø–∏—Å–∏
    if args.mode == 'record' and args.bitrate == 6000000:  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        args.bitrate = 8000000  # 8 Mbps –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–∏
        logger.info("üìπ –†–µ–∂–∏–º –∑–∞–ø–∏—Å–∏: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –±–∏—Ç—Ä–µ–π—Ç 8 Mbps (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)")
        logger.info("   –î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: --bitrate <–∑–Ω–∞—á–µ–Ω–∏–µ>")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    if args.source == "files":
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        for vf in [args.video1, args.video2]:
            if not os.path.exists(vf):
                logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {vf}")
                return 1
    else:
        # –î–ª—è –∫–∞–º–µ—Ä –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–∞
        try:
            cam1 = int(args.video1)
            cam2 = int(args.video2)
            args.video1 = str(cam1)
            args.video2 = str(cam2)
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–º–µ—Ä—ã: {cam1} –∏ {cam2}")
        except ValueError:
            logger.error("–î–ª—è –∫–∞–º–µ—Ä —É–∫–∞–∂–∏—Ç–µ —á–∏—Å–ª–æ–≤—ã–µ ID (–Ω–∞–ø—Ä–∏–º–µ—Ä: --video1 0 --video2 1)")
            return 1

    app = PanoramaWithVirtualCamera(
        source_type=args.source,
        video1=args.video1,
        video2=args.video2,
        config_path=args.config,
        buffer_duration=args.buffer,
        enable_display=not args.disable_display,
        display_mode=args.mode,
        enable_analysis=not args.disable_analysis,
        analysis_skip_interval=args.skip_interval,
        confidence_threshold=args.confidence,
        auto_zoom=not args.no_zoom,
        stream_url=args.stream_url,
        stream_key=args.stream_key,
        output_file=args.output,
        bitrate=args.bitrate
    )

    ok = app.run()
    return 0 if ok else 1


if __name__ == "__main__":
    sys.exit(main())
