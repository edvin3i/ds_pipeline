

<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" type="text/javascript"
  data-document-language="true" charset="UTF-8" data-domain-script="3e2b62ff-7ae7-4ac5-87c8-d5949ecafff5">
</script>
<script type="text/javascript">
  function OptanonWrapper() {
    var event = new Event('bannerLoaded');
    window.dispatchEvent(event);
  }
</script>
<script src="https://images.nvidia.com/aem-dam/Solutions/ot-js/ot-custom.js" type="text/javascript">
</script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Gst-nvinfer &#8212; DeepStream documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css%3Fdigest=dfe6caa3a7d634c4db9b.css" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css%3Fdigest=dfe6caa3a7d634c4db9b.css" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css%3Fdigest=dfe6caa3a7d634c4db9b.css" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css%3Fdigest=dfe6caa3a7d634c4db9b.css" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css%3Fv=a746c00c.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/nvidia-sphinx-theme.css%3Fv=eb367b29.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css%3Fv=7abaf8bc.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css%3Fv=95c83b7e.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js%3Fdigest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js%3Fdigest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js%3Fdigest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js%3Fv=22d9b4cb"></script>
    <script src="../_static/doctools.js%3Fv=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js%3Fv=dc90522c"></script>
    <script src="../_static/design-tabs.js%3Fv=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'text/DS_plugin_gst-nvinfer';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '../versions1.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '7.1';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/version-patch.js%3Fv=c24f8c5d"></script>
    <link rel="icon" href="../_static/Nvidia.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Gst-nvinferserver" href="DS_plugin_gst-nvinferserver.html" />
    <link rel="prev" title="Gst-nvdspreprocess (Alpha)" href="DS_plugin_gst-nvdspreprocess.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Sep 15, 2025"/>

    <script src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js" ></script>
    


  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="DS_plugin_gst-nvinfer.html#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="DeepStream documentation - Home"/>
    <script>document.write(`<img src="../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark" alt="DeepStream documentation - Home"/>`);</script>
  
  
    <p class="title logo__title">DeepStream documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="DeepStream documentation - Home"/>
    <script>document.write(`<img src="../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark" alt="DeepStream documentation - Home"/>`);</script>
  
  
    <p class="title logo__title">DeepStream documentation</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">


<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Overview.html">Welcome to the DeepStream Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_Migration_guide.html">Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_Quickstart.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_docker_containers.html">Docker Containers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Samples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_C_Sample_Apps.html">C/C++ Sample Apps Source Details</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_Python_Sample_Apps.html">Python Sample Apps and Bindings Source Details</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_ref_app_deepstream.html">DeepStream Reference Application - deepstream-app</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_ref_app_test5.html">DeepStream Reference Application - deepstream-test5 app</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_ref_app_nmos.html">DeepStream Reference Application - deepstream-nmos app</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_ref_app_github.html">DeepStream Reference Application on GitHub</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_sample_configs_streams.html">Sample Configurations and Streams</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_sample_custom_gstream.html">Implementing a Custom GStreamer Plugin with OpenCV Integration Example</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TAO toolkit Integration with DeepStream</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_TAO_integration.html">TAO Toolkit Integration with DeepStream</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials and How-to's</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_3D_Custom_Manual.html">DeepStream-3D Custom Apps and Libs Tutorials</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Performance</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Performance.html">Performance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Accuracy</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Accuracy.html">Accuracy Tuning Tools</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Custom Model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_using_custom_model.html">Using a Custom Model with DeepStream</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Key Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_3D_MultiModal_Lidar_Sensor_Fusion.html">DeepStream-3D Sensor Fusion Multi-Modal Application and Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_3D_MultiModal_Lidar_Camera_BEVFusion.html">DeepStream-3D Multi-Modal BEVFusion Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_3D_MultiModal_Lidar_Camera_V2XFusion.html">DeepStream-3D Multi-Modal V2XFusion Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_Smart_video.html">Smart Video Record</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_IoT.html">IoT</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_on_the_fly_model.html">On the Fly Model Update</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_NTP_Timestamp.html">NTP Timestamp in DeepStream</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_AVSync.html">AV Sync in DeepStream</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_RestServer.html">DeepStream With REST API Sever</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_3D_Action.html">DeepStream 3D Action Recognition App</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_3D_Depth_Camera.html">DeepStream 3D Depth Camera App</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_3D_Lidar_Inference.html">DeepStream 3D Lidar Inference App</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_library_nvdsnmos.html">Networked Media Open Specifications (NMOS) in DeepStream</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_postprocessing_plugin.html">Gst-nvdspostprocess in DeepStream</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_Can_Orientation.html">DeepStream Can Orientation App</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Application Migration</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Application_migration.html">Application Migration to DeepStream 7.1 from DeepStream 7.0</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Plugin Guide</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="DS_plugin_Intro.html">GStreamer Plugin Overview</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_metadata.html">MetaData in the DeepStream SDK</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdspreprocess.html">Gst-nvdspreprocess (Alpha)</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="DS_plugin_gst-nvinfer.html#">Gst-nvinfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvinferserver.html">Gst-nvinferserver</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvtracker.html">Gst-nvtracker</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvstreammux.html">Gst-nvstreammux</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvstreammux2.html">Gst-nvstreammux New</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvstreamdemux.html">Gst-nvstreamdemux</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvmultistreamtiler.html">Gst-nvmultistreamtiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsosd.html">Gst-nvdsosd</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsmetautils.html">Gst-nvdsmetautils</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsvideotemplate.html">Gst-nvdsvideotemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsaudiotemplate.html">Gst-nvdsaudiotemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvvideoconvert.html">Gst-nvvideoconvert</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdewarper.html">Gst-nvdewarper</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvof.html">Gst-nvof</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvofvisual.html">Gst-nvofvisual</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvsegvisual.html">Gst-nvsegvisual</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvvideo4linux2.html">Gst-nvvideo4linux2</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvjpegdec.html">Gst-nvjpegdec</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvimagedec.html">Gst-nvimagedec</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvjpegenc.html">Gst-nvjpegenc</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvimageenc.html">Gst-nvimageenc</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvmsgconv.html">Gst-nvmsgconv</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvmsgbroker.html">Gst-nvmsgbroker</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsanalytics.html">Gst-nvdsanalytics</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsudpsrc.html">Gst-nvdsudpsrc</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsudpsink.html">Gst-nvdsudpsink</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdspostprocess.html">Gst-nvdspostprocess (Alpha)</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvds3dfilter.html">Gst-nvds3dfilter</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvds3dbridge.html">Gst-nvds3dbridge</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvds3dmixer.html">Gst-nvds3dmixer</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsucx.html">Gst-NvDsUcx</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvdsxfer.html">Gst-nvdsxfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvvideotestsrc.html">Gst-nvvideotestsrc</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvmultiurisrcbin.html">Gst-nvmultiurisrcbin</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_plugin_gst-nvurisrcbin.html">Gst-nvurisrcbin</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Troubleshooting and FAQ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_FAQ.html">Frequently Asked Questions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream On WSL2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_on_WSL2.html">DeepStream On WSL</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_WSL2_FAQ.html">FAQ for Deepstream On WSL</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream API Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_API_Guide.html">DeepStream API Guides</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Service Maker</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_service_maker_intro.html">What is Deepstream Service Maker</a></li>
<li class="toctree-l1"><a class="reference internal" href="DS_service_maker_cpp.html">Service Maker for C/C++ Developers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="DS_service_maker_python.html">Service Maker for Python Developers(alpha)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="DS_service_maker_python_quick_start.html">Quick Start Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_service_maker_python_into_to_flow_api.html">Introduction to Flow APIs</a></li>

<li class="toctree-l2"><a class="reference internal" href="DS_service_maker_python_into_to_pipeline_api.html">Introduction to Pipeline APIs</a></li>

<li class="toctree-l2"><a class="reference internal" href="DS_service_maker_python_advanced_features.html">Advanced Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="DS_service_maker_traditional_app_migration.html">Migrating Traditional Deepstream Apps to Service Maker Apps in Python</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="DS_service_maker_plugin.html">What is a Deepstream Service Maker Plugin</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deepstream Libraries</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Libraries.html">DeepStream Libraries (Developer Preview)</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Graph Composer</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_intro.html">Overview</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Platforms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Platforms.html">Supported platforms</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Getting_Started.html">Application Development Workflow</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_GraphComposer_Create_Graph.html">Creating an AI Application</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Zero_Coding_Sample_Graphs.html">Reference graphs</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Dev_Workflow.html">Extension Development Workflow</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Zero_Coding_Developing_Extension.html">Developing Extensions for DeepStream</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Zero_Coding_DS_Components.html">DeepStream Components</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">GXF Internals</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GXF_Internals.html">GXF Internals</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Graph eXecution Engine</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Graph_Runtime.html">Graph Execution Engine</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Graph Composer Containers</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Containers.html">Graph Composer and GXF Containers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">GXF Component Interfaces</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GXF_Component_Interfaces.html">GXF Component Interfaces</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">GXF Application API's</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GXF_App_C++_APIs.html">GXF App C++ APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GXF_App_Python_APIs.html">GXF App Python APIs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">GXF Runtime API's</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GXF_Core_C++_APIs.html">GXF Core C++ APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GXF_Core_C_APIs.html">GXF Core C APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GXF_Core_Python_APIs.html">GXF Core Python APIs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Extension Manual</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="Extensionmanual_toc.html">Extensions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/CudaExtension.html">CudaExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/StreamSync.html">GXF Stream Sync</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/StandardExtension.html">StandardExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/Python_Codelet.html">Python Codelets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/NetworkExtension.html">NetworkExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/NvTritonExt.html">NvTritonExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/SerializationExtension.html">SerializationExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/MultimediaExtension.html">MultimediaExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/VideoEncoderExtension.html">VideoEncoderExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/VideoDecoderExtension.html">VideoDecoderExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/Behavior_Tree.html">Behavior Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/UcxExtension.html">UCX Extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/HttpExtension.html">HttpExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/GrpcExtension.html">GrpcExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../graphtools-docs/docs/text/ExtensionsManual/TensorrtExtension.html">TensorRTExtension</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDs3dProcessingExt.html">NvDs3dProcessingExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsActionRecognitionExt.html">NvDsActionRecognitionExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsAnalyticsExt.html">NvDsAnalyticsExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsBaseExt.html">NvDsBaseExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsCloudMsgExt.html">NvDsCloudMsgExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsConverterExt.html">NvDsConverterExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsDewarperExt.html">NvDsDewarperExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsInferenceExt.html">NvDsInferenceExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsInferenceUtilsExt.html">NvDsInferenceUtilsExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsInterfaceExt.html">NvDsInterfaceExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsMuxDemuxExt.html">NvDsMuxDemuxExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsOpticalFlowExt.html">NvDsOpticalFlowExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsOutputSinkExt.html">NvDsOutputSinkExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsSampleExt.html">NvDsSampleExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsSampleModelsExt.html">NvDsSampleModelsExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsSourceExt.html">NvDsSourceExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsTemplateExt.html">NvDsTemplateExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsTrackerExt.html">NvDsTrackerExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsTranscodeExt.html">NvDsTranscodeExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsTritonExt.html">NvDsTritonExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsUcxExt.html">NvDsUcxExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsUdpExt.html">NvDsUdpExt</a></li>
<li class="toctree-l2"><a class="reference internal" href="ExtensionsManual/NvDsVisualizationExt.html">NvDsVisualizationExt</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tools</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Registry.html">Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Registry_CLI.html">Registry Command Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Composer.html">Composer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_Container_Builder.html">Container Builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_gxf_CLI.html">GXF Command Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="Pipetuner-guide.html">Pipetuner Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FAQ Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../graphtools-docs/docs/text/GraphComposer_FAQ.html">FAQ</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Legal Information</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DS_Legal.html">DeepStream End User License Agreement</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">DeepStream Feedback</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DeepStream_Main_Feedback_Form.html">Feedback form</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">


<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
  </div>
  
  <div id="rtd-footer-container"></div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="DS_plugin_Intro.html" class="nav-link">GStreamer Plugin Overview</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Gst-nvinfer</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="gst-nvinfer">
<span id="ds-plugin-nvinfer"></span><h1>Gst-nvinfer<a class="headerlink" href="DS_plugin_gst-nvinfer.html#gst-nvinfer" title="Link to this heading">#</a></h1>
<p>The Gst-nvinfer plugin does inferencing on input data using NVIDIA<sup>®</sup> TensorRT™.</p>
<p>The plugin accepts batched <cite>NV12/RGBA</cite> buffers from upstream. The <cite>NvDsBatchMeta</cite> structure must already be attached to the Gst Buffers.
The low-level library (<cite>libnvds_infer</cite>) operates on any of INT8 RGB, BGR, or GRAY data with dimension of Network Height and Network Width.
The Gst-nvinfer plugin performs transforms (format conversion and scaling), on the input frame based on network requirements, and passes the transformed data to the low-level library.
The low-level library preprocesses the transformed frames (performs normalization and mean subtraction) and produces final float <cite>RGB/BGR/GRAY</cite> planar data which is passed to the TensorRT engine for inferencing. The output type generated by the low-level library depends on the network type.
The pre-processing function is:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">net</span> <span class="pre">scale</span> <span class="pre">factor*(x-mean)</span></code></p>
</div></blockquote>
<p>Where:</p>
<ul class="simple">
<li><p>x is the input pixel value. It is an int8 with range [0,255].</p></li>
<li><p>mean is the corresponding mean value, read either from the mean file or as offsets[c], where c is the channel to which the input pixel belongs, and offsets is the array specified in the configuration file. It is a float.</p></li>
<li><p>net-scale-factor is the pixel scaling factor specified in the configuration file. It is a float.</p></li>
<li><p>y is the corresponding output pixel value. It is a float.</p></li>
</ul>
<p>Gst-nvinfer currently works on the following type of networks:</p>
<ul class="simple">
<li><p>Multi-class object detection</p></li>
<li><p>Multi-label classification</p></li>
<li><p>Segmentation (semantic)</p></li>
<li><p>Instance Segmentation</p></li>
</ul>
<p>The Gst-nvinfer plugin can work in three modes:</p>
<ul class="simple">
<li><p>Primary mode: Operates on full frames</p></li>
<li><p>Secondary mode: Operates on objects added in the meta by upstream components</p></li>
<li><p>Preprocessed Tensor Input mode: Operates on tensors attached by upstream components</p></li>
</ul>
<p>When operating in preprocessed tensor input mode, the pre-processing inside Gst-nvinfer is completely
skipped. The plugin looks for <code class="docutils literal notranslate"><span class="pre">GstNvDsPreProcessBatchMeta</span></code> attached to the input
buffer and passes the tensor as is to TensorRT inference function without any
modifications. This mode currently supports processing on full-frame and ROI. The
GstNvDsPreProcessBatchMeta is attached by the Gst-nvdspreprocess plugin.</p>
<p>When the plugin is operating as a secondary classifier along with the tracker, it tries to improve performance by avoiding re-inferencing on the same objects in every frame. It does this by caching the classification output in a map with the object’s unique ID as the key. The object is inferred upon only when it is first seen in a frame (based on its object ID) or when the size (bounding box area) of the object increases by 20% or more. This optimization is possible only when the tracker is added as an upstream element.
Detailed documentation of the TensorRT interface is available at:
<a class="reference external" href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html">https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html</a>
The plugin supports the IPlugin interface for custom layers. Refer to section IPlugin Interface for details.
The plugin also supports the interface for custom functions for parsing outputs of object detectors and initialization of non-image input layers in cases where there is more than one input layer.
Refer to sources/includes/nvdsinfer_custom_impl.h for the custom method implementations for custom models.</p>
<blockquote>
<div><img alt="Gst-nvinfer" class="align-center" src="../_images/DS_plugin_gst-nvinfer.png" />
</div></blockquote>
<p>Downstream components receive a Gst Buffer with unmodified contents plus the metadata created from the inference output of the Gst-nvinfer plugin.
The plugin can be used for cascaded inferencing. That is, it can perform primary inferencing directly on input data, then perform secondary inferencing on the results of primary inferencing, and so on. See the sample application deepstream-test2 for more details.</p>
<section id="inputs-and-outputs">
<h2>Inputs and Outputs<a class="headerlink" href="DS_plugin_gst-nvinfer.html#inputs-and-outputs" title="Link to this heading">#</a></h2>
<p>This section summarizes the inputs, outputs, and communication facilities of the Gst-nvinfer plugin.</p>
<ul class="simple">
<li><p>Inputs</p>
<ul>
<li><p>Gst Buffer</p></li>
<li><p>NvDsBatchMeta (attaching NvDsFrameMeta)</p></li>
<li><p>ONNX</p></li>
<li><p>TAO Encoded Model and Key</p></li>
<li><p>Offline: Supports engine files generated by TAO Toolkit SDK Model converters</p></li>
<li><p>Layers: Supports all layers supported by TensorRT, see: <a class="reference external" href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html">https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html</a>.</p></li>
</ul>
</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul class="simple">
<li><p>Control parameters</p></li>
</ul>
<blockquote>
<div><p>Gst-nvinfer gets control parameters from a configuration file. You can specify this by setting the property config-file-path. For details, see Gst-nvinfer File Configuration Specifications. Other control parameters that can be set through GObject properties are:</p>
<blockquote>
<div><ul class="simple">
<li><p>Batch size</p></li>
<li><p>Inference interval</p></li>
<li><p>Attach inference tensor outputs as buffer metadata</p></li>
<li><p>Attach instance mask output as in object metadata</p></li>
<li><p>The parameters set through the GObject properties override the parameters in the Gst-nvinfer configuration file.</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<ul class="simple">
<li><p>Outputs</p>
<ul>
<li><p>Gst Buffer</p></li>
<li><p>Depending on network type and configured parameters, one or more of:</p></li>
<li><p>NvDsObjectMeta</p></li>
<li><p>NvDsClassifierMeta</p></li>
<li><p>NvDsInferSegmentationMeta</p></li>
<li><p>NvDsInferTensorMeta</p></li>
</ul>
</li>
</ul>
</section>
<section id="features">
<h2>Features<a class="headerlink" href="DS_plugin_gst-nvinfer.html#features" title="Link to this heading">#</a></h2>
<p>The following table summarizes the features of the plugin.</p>
<blockquote>
<div><div class="pst-scrollable-table-container"><table class="table" id="id1">
<caption><span class="caption-text">Gst-nvinfer plugin features</span><a class="headerlink" href="DS_plugin_gst-nvinfer.html#id1" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 33.3%" />
<col style="width: 33.3%" />
<col style="width: 33.3%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Feature</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Release</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Explicit Full Dimension Network Support</p></td>
<td><p>Refer to <a class="reference external" href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#work_dynamic_shapes">https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#work_dynamic_shapes</a> for more details.</p></td>
<td><p>DS 5.0</p></td>
</tr>
<tr class="row-odd"><td><p>Non-maximum Suppression (NMS)</p></td>
<td><p>New bounding box clustering algorithm.</p></td>
<td><p>DS 5.0</p></td>
</tr>
<tr class="row-even"><td><p>On-the-fly model update (Engine file only)</p></td>
<td><p>Update the model-engine-file on-the-fly in a running pipeline.</p></td>
<td><p>DS 5.0</p></td>
</tr>
<tr class="row-odd"><td><p>Configurable frame scaling params</p></td>
<td><p>Configurable options to select the compute hardware and the filter to use while scaling frame/object crops to network resolution</p></td>
<td><p>DS 5.0</p></td>
</tr>
<tr class="row-even"><td><p>TAO toolkit encoded model support</p></td>
<td><p>—</p></td>
<td><p>DS 4.0</p></td>
</tr>
<tr class="row-odd"><td><p>Gray input model support</p></td>
<td><p>Support for models with single channel gray input</p></td>
<td><p>DS 4.0</p></td>
</tr>
<tr class="row-even"><td><p>Tensor output as meta</p></td>
<td><p>Raw tensor output is attached as meta data to Gst Buffers and flowed through the pipeline</p></td>
<td><p>DS 4.0</p></td>
</tr>
<tr class="row-odd"><td><p>Segmentation model</p></td>
<td><p>Supports segmentation model</p></td>
<td><p>DS 4.0</p></td>
</tr>
<tr class="row-even"><td><p>Maintain input aspect ratio</p></td>
<td><p>Configurable support for maintaining aspect ratio when scaling input frame to network resolution</p></td>
<td><p>DS 4.0</p></td>
</tr>
<tr class="row-odd"><td><p>Custom cuda engine creation interface</p></td>
<td><p>Interface for generating CUDA engines from TensorRT INetworkDefinition and IBuilder APIs instead of model files</p></td>
<td><p>DS 4.0</p></td>
</tr>
<tr class="row-even"><td><p>ONNX Model support</p></td>
<td><p>—</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-odd"><td><p>Multiple modes of operation</p></td>
<td><p>Support for cascaded inferencing</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Asynchronous mode of operation for secondary inferencing</p></td>
<td><p>Infer asynchronously for secondary classifiers</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Grouping using CV::Group rectangles</p></td>
<td><p>For detector bounding box clustering</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Configurable batch-size processing</p></td>
<td><p>User can configure batch size for processing</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>No Restriction on number of output blobs</p></td>
<td><p>Supports any number of output blobs</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-even"><td><p>Configurable number of detected classes (detectors)</p></td>
<td><p>Supports configurable number of detected classes</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-odd"><td><p>Support for Classes: configurable (&gt; 32)</p></td>
<td><p>Supports any number of classes</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-even"><td><p>Application access to raw inference output</p></td>
<td><p>Application can access inference output buffers for user specified layer</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-odd"><td><p>Support for single shot detector (SSD)</p></td>
<td><p>—</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-even"><td><p>Secondary GPU Inference Engines (GIEs) operate as detector on primary bounding box</p></td>
<td><p>Supports secondary inferencing as detector</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Multiclass secondary support</p></td>
<td><p>Supports multiple classifier network outputs</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Grouping using DBSCAN</p></td>
<td><p>For detector bounding box clustering</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-odd"><td><p>Loading an external lib containing IPlugin implementation for custom layers (IPluginCreator &amp; IPluginFactory)</p></td>
<td><p>Supports loading (dlopen()) a library containing IPlugin implementation for custom layers</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-even"><td><p>Multi GPU</p></td>
<td><p>Select GPU on which we want to run inference</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Detection width height configuration</p></td>
<td><p>Filter out detected objects based on min/max object size threshold</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Allow user to register custom parser</p></td>
<td><p>Supports final output layer bounding box parsing for custom detector network</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Bounding box filtering based on configurable object size</p></td>
<td><p>Supports inferencing in secondary mode objects meeting min/max size threshold</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Configurable operation interval</p></td>
<td><p>Interval for inferencing (number of batched buffers skipped)</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Select Top and bottom regions of interest (RoIs)</p></td>
<td><p>Removes detected objects in top and bottom areas</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Operate on Specific object type (Secondary mode)</p></td>
<td><p>Process only objects of define classes for secondary inferencing</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Configurable blob names for parsing bounding box (detector)</p></td>
<td><p>Support configurable names for output blobs for detectors</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Allow configuration file input</p></td>
<td><p>Support configuration file as input (mandatory in DS 3.0)</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Allow selection of class id for operation</p></td>
<td><p>Supports secondary inferencing based on class ID</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Support for Full Frame Inference: Primary as a classifier</p></td>
<td><p>Can work as classifier as well in primary mode</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Multiclass secondary support</p></td>
<td><p>Support multiple classifier network outputs</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Secondary GIEs operate as detector on primary bounding box 
Support secondary inferencing as detector</p></td>
<td><p>—</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Supports FP16, FP32 and INT8 models
FP16 and INT8 are platform dependent</p></td>
<td><p>—</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-even"><td><p>Supports TensorRT Engine file as input</p></td>
<td><p>—</p></td>
<td><p>DS 2.0</p></td>
</tr>
<tr class="row-odd"><td><p>Inference input layer initialization
Initializing non-video input layers in case of more than one input layers</p></td>
<td><p>—</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-even"><td><p>Support for FasterRCNN</p></td>
<td><p>—</p></td>
<td><p>DS 3.0</p></td>
</tr>
<tr class="row-odd"><td><p>Support for Yolo detector (YoloV3/V3-tiny/V2/V2-tiny)</p></td>
<td><p>—</p></td>
<td><p>DS 4.0</p></td>
</tr>
<tr class="row-even"><td><p>Support for yolov3-spp detector</p></td>
<td><p>—</p></td>
<td><p>DS 5.0</p></td>
</tr>
<tr class="row-odd"><td><p>Support Instance segmentation with MaskRCNN</p></td>
<td><p>Support for instance segmentation using MaskRCNN. It includes output parser and attach mask in object metadata.</p></td>
<td><p>DS 5.0</p></td>
</tr>
<tr class="row-even"><td><p>Support for NHWC network input</p></td>
<td><p>—</p></td>
<td><p>DS 6.0</p></td>
</tr>
<tr class="row-odd"><td><p>Added support for TAO ONNX model</p></td>
<td><p>—</p></td>
<td><p>DS 6.0</p></td>
</tr>
<tr class="row-even"><td><p>Support for input tensor meta</p></td>
<td><p>Inferences using already preprocessed raw tensor from input tensor meta (attached as user meta at batch level) and skips preprocessing in nvinfer. In this mode, the batch-size of nvinfer must be equal to the sum of ROIs set in the gst-nvdspreprocess plugin config file.</p></td>
<td><p>DS 6.0</p></td>
</tr>
<tr class="row-odd"><td><p>Support for clipping bounding boxes to ROI boundary</p></td>
<td><p>—</p></td>
<td><p>DS 6.2</p></td>
</tr>
</tbody>
</table>
</div>
</div></blockquote>
</section>
<section id="gst-nvinfer-file-configuration-specifications">
<h2>Gst-nvinfer File Configuration Specifications<a class="headerlink" href="DS_plugin_gst-nvinfer.html#gst-nvinfer-file-configuration-specifications" title="Link to this heading">#</a></h2>
<p>The Gst-nvinfer configuration file uses a “Key File” format described in <a class="reference external" href="https://specifications.freedesktop.org/desktop-entry-spec/latest">https://specifications.freedesktop.org/desktop-entry-spec/latest</a>.
The <code class="docutils literal notranslate"><span class="pre">[property]</span></code> group configures the general behavior of the plugin. It is the only mandatory group.
The <code class="docutils literal notranslate"><span class="pre">[class-attrs-all]</span></code> group configures detection parameters for all classes.
The <code class="docutils literal notranslate"><span class="pre">[class-attrs-&lt;class-id&gt;]</span></code> group configures detection parameters for a class specified by <cite>&lt;class-id&gt;</cite>. For example, the <code class="docutils literal notranslate"><span class="pre">[class-attrs-23]</span></code> group configures detection parameters for class ID <cite>23</cite>. This type of group has the same keys as <code class="docutils literal notranslate"><span class="pre">[class-attrs-all]</span></code>.
The following two tables respectively describe the keys supported for <code class="docutils literal notranslate"><span class="pre">[property]</span></code> groups and <code class="docutils literal notranslate"><span class="pre">[class-attrs-…]</span></code> groups.</p>
<blockquote>
<div><div class="pst-scrollable-table-container"><table class="table" id="id2">
<caption><span class="caption-text">Gst-nvinfer Property Group Supported Keys</span><a class="headerlink" href="DS_plugin_gst-nvinfer.html#id2" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 14.3%" />
<col style="width: 14.3%" />
<col style="width: 14.3%" />
<col style="width: 14.3%" />
<col style="width: 14.3%" />
<col style="width: 14.3%" />
<col style="width: 14.3%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Meaning</p></th>
<th class="head"><p>Type and Range</p></th>
<th class="head"><p>Example
Notes</p></th>
<th class="head"><div class="line-block">
<div class="line">Network Types</div>
<div class="line">/ Applicable to GIEs </div>
<div class="line">(Primary/­Secondary)</div>
</div>
</th>
<th class="head"></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>num-detected-classes</p></td>
<td><p>Number of classes detected by the network</p></td>
<td><p>Integer, &gt;0</p></td>
<td><p>num-detected-classes=­91</p></td>
<td><p>Detector</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>net-scale-factor</p></td>
<td><p>Pixel normalization factor (ignored if input-tensor-meta enabled)</p></td>
<td><p>Float, &gt;0.0</p></td>
<td><p>net-scale-factor=­0.031</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>model-file</p></td>
<td><p>Pathname of the model file. Not required if model-engine-file is used</p></td>
<td><p>String</p></td>
<td><p>model-file=</p>
<p>/home/­ubuntu/­model</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>proto-file</p></td>
<td><p>Pathname of the prototxt file. Not required if model-engine-file is used</p></td>
<td><p>String</p></td>
<td><p>proto-file=</p>
<p>/home/­ubuntu/­model.prototxt</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>int8-calib-file</p></td>
<td><p>Pathname of the INT8 calibration file for dynamic range adjustment with an FP32 model</p></td>
<td><p>String</p></td>
<td><p>int8-calib-file=­/home/­ubuntu/­int8_calib</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>batch-size</p></td>
<td><p>Number of frames or objects to be inferred together in a batch</p></td>
<td><p>Integer, &gt;0</p></td>
<td><p>batch-size=30</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>input-tensor-from-meta</p></td>
<td><p>Use preprocessed input tensors attached as metadata instead of preprocessing inside the plugin. If this is set, ensure that the batch-size of nvinfer is equal to the sum of ROIs set in the gst-nvdspreprocess plugin config file.</p></td>
<td><p>Boolean</p></td>
<td><p>input-tensor-from-meta=1</p></td>
<td><p>All</p>
<p>Primary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>tensor-meta-pool-size</p></td>
<td><p>Size of the output tensor meta pool</p></td>
<td><p>Integer, &gt;0</p></td>
<td><p>tensor-meta-pool-size=20</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>model-engine-file</p></td>
<td><p>Pathname of the serialized model engine file</p></td>
<td><p>String</p></td>
<td><p>model-engine-file=</p>
<p>/home/­ubuntu/­model.engine</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>onnx-file</p></td>
<td><p>Pathname of the ONNX model file</p></td>
<td><p>String</p></td>
<td><p>onnx-file=</p>
<p>/home/­ubuntu/­model.onnx</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>enable-dbscan</p></td>
<td><p>Indicates whether to use DBSCAN or the OpenCV groupRectangles() function for grouping detected objects.
DEPRECATED. Use cluster-mode instead.</p></td>
<td><p>Boolean</p></td>
<td><p>enable-dbscan=1</p></td>
<td><p>Detector</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>labelfile-path</p></td>
<td><p>Pathname of a text file containing the labels for the model</p></td>
<td><p>String</p></td>
<td><p>labelfile-path=</p>
<p>/home/­ubuntu/­model_labels.txt</p>
</td>
<td><p>Detector &amp; classifier</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>mean-file</p></td>
<td><p>Pathname of mean data file in PPM format (ignored if input-tensor-meta enabled)</p></td>
<td><p>String</p></td>
<td><p>mean-file=­</p>
<p>/home/­ubuntu/­model_meanfile.ppm</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>gie-unique-id</p></td>
<td><p>Unique ID to be assigned to the GIE to enable the application and other elements to identify detected bounding boxes and labels</p></td>
<td><p>Integer, &gt;0</p></td>
<td><p>gie-unique-id=2</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>operate-on-gie-id</p></td>
<td><p>Unique ID of the GIE on whose metadata (bounding boxes) this GIE is to operate on</p></td>
<td><p>Integer, &gt;0</p></td>
<td><p>operate-on-gie-id=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>operate-on-class-ids</p></td>
<td><p>Class IDs of the parent GIE on which this GIE is to operate on</p></td>
<td><p>Semicolon delimited integer array</p></td>
<td><p>operate-on-class-ids=1;2</p>
<p>Operates on objects with class IDs 1, 2</p>
<p>generated by parent GIE</p>
<p>If operate-on-class-ids is set to -1,</p>
<p>it will operate on all class-ids</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>interval</p></td>
<td><p>Specifies the number of consecutive batches to be skipped for inference</p></td>
<td><p>Integer, &gt;0</p></td>
<td><p>interval=1</p></td>
<td><p>All</p>
<p>Primary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>input-object-min-width</p></td>
<td><p>Secondary GIE infers only on objects with this minimum width</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>input-object-min-width=40</p></td>
<td><p>All</p>
<p>Secondary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>input-object-min-height</p></td>
<td><p>Secondary GIE infers only on objects with this minimum height</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>input-object-min-height=40</p></td>
<td><p>All</p>
<p>Secondary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>input-object-max-width</p></td>
<td><p>Secondary GIE infers only on objects with this maximum width</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>input-object-max-width=256</p>
<p>0 disables the threshold</p>
</td>
<td><p>All</p>
<p>Secondary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>input-object-max-height</p></td>
<td><p>Secondary GIE infers only on objects with this maximum height</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>input-object-max-height=256</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>network-mode</p></td>
<td><p>Data format to be used by inference</p></td>
<td><p>Integer
0: FP32
1: INT8
2: FP16
3: BEST</p></td>
<td><p>network-mode=0</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>offsets</p></td>
<td><p>Array of mean values of color components to be subtracted from each pixel. Array length must equal the number of color components in the frame. The plugin multiplies mean values by net-scale-factor.(ignored if input-tensor-meta enabled)</p></td>
<td><p>Semicolon delimited float array, all values ≥0</p></td>
<td><p>offsets=77.5 21.2</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>parse-bbox-func-name</p></td>
<td><p>Name of the custom bounding box parsing function. If not specified, Gst-nvinfer uses the internal function for the resnet model provided by the SDK</p></td>
<td><p>String</p></td>
<td><p>parse-bbox-func-name=</p>
<p>parse_bbox_resnet</p>
</td>
<td><p>Detector</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>parse-bbox-instance-mask-func-name</p></td>
<td><p>Name of the custom instance segmentation parsing function. It is mandatory for instance segmentation network as there is no internal function.</p></td>
<td><p>String</p></td>
<td><p>parse-bbox-instance-mask-func-name=</p>
<p>NvDsInferParseCustomMrcnnTLT</p>
</td>
<td><p>Instance Segmentation</p>
<p>Primary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>custom-lib-path</p></td>
<td><p>Absolute pathname of a library containing custom method implementations for custom models</p></td>
<td><p>String</p></td>
<td><p>custom-lib-path=</p>
<p>/home/­ubuntu/­libresnet_custom_impl.so</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>model-color-format</p></td>
<td><p>Color format required by the model (ignored if input-tensor-meta enabled)</p></td>
<td><p>Integer
0: RGB
1: BGR
2: GRAY</p></td>
<td><p>model-color-format=0</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>classifier-async-mode</p></td>
<td><p>Enables inference on detected objects and asynchronous metadata attachments. Works only when tracker-ids are attached. Pushes buffer downstream without waiting for inference results. Attaches metadata after the inference results are available to next Gst Buffer in its internal queue.</p></td>
<td><p>Boolean</p></td>
<td><p>classifier-async-mode=1</p></td>
<td><p>Classifier</p>
<p>Secondary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>process-mode</p></td>
<td><p>Mode (primary or secondary) in which the element is to operate on (ignored if input-tensor-meta enabled)</p></td>
<td><p>Integer
1=Primary
2=Secondary</p></td>
<td><p>gie-mode=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>classifier-threshold</p></td>
<td><p>Minimum threshold label probability. The GIE outputs the label having the highest probability if it is greater than this threshold</p></td>
<td><p>Float, ≥0</p></td>
<td><p>classifier-threshold=0.4</p></td>
<td><p>Classifier</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>secondary-reinfer-interval</p></td>
<td><p>Re-inference interval for objects, in frames</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>secondary-reinfer-interval=15</p></td>
<td><p>Detector &amp; Classifier</p>
<p>Secondary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>output-tensor-meta</p></td>
<td><p>Gst-nvinfer attaches raw tensor output as Gst Buffer metadata.</p></td>
<td><p>Boolean</p></td>
<td><p>output-tensor-meta=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>output-instance-mask</p></td>
<td><p>Gst-nvinfer attaches instance mask output in object metadata.</p></td>
<td><p>Boolean</p></td>
<td><p>output-instance-mask=1</p></td>
<td><p>Instance Segmentation</p>
<p>Primary</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>enable-dla</p></td>
<td><p>Indicates whether to use the DLA engine for inferencing.
Note: DLA is supported only on NVIDIA® Jetson AGX Orin™ and NVIDIA® Jetson Orin NX™. Currently work in progress.</p></td>
<td><p>Boolean</p></td>
<td><p>enable-dla=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>use-dla-core</p></td>
<td><p>DLA core to be used.
Note: Supported only on Jetson AGX Orin and Jetson Orin NX. Currently work in progress.</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>use-dla-core=0</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>network-type</p></td>
<td><p>Type of network</p></td>
<td><p>Integer</p>
<p>0: Detector</p>
<p>1: Classifier</p>
<p>2: Segmentation</p>
<p>3: Instance Segmentation</p>
</td>
<td><p>network-type=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>maintain-aspect-ratio</p></td>
<td><p>Indicates whether to maintain aspect ratio while scaling input.</p></td>
<td><p>Boolean</p></td>
<td><p>maintain-aspect-ratio=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>symmetric-padding</p></td>
<td><p>Indicates whether to pad image symmetrically while scaling input. DeepStream pads the images asymmetrically by default.</p></td>
<td><p>Boolean</p></td>
<td><p>symmetric-padding=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>parse-classifier-func-name</p></td>
<td><p>Name of the custom classifier output parsing function. If not specified, Gst-nvinfer uses the internal parsing function for softmax layers.</p></td>
<td><p>String</p></td>
<td><p>parse-classifier-func-name=­</p>
<p>parse_bbox_softmax</p>
</td>
<td><p>Classifier</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>custom-network-config</p></td>
<td><p>Pathname of the configuration file for custom networks available in the custom interface for creating CUDA engines.</p></td>
<td><p>String</p></td>
<td><p>custom-network-config=</p>
<p>/home/­ubuntu/­network.config</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>tlt-encoded-model</p></td>
<td><p>Pathname of the TAO toolkit encoded model.</p></td>
<td><p>String</p></td>
<td><p>tlt-encoded-model=­</p>
<p>/home/­ubuntu/­model.etlt</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>tlt-model-key</p></td>
<td><p>Key for the TAO toolkit encoded model.</p></td>
<td><p>String</p></td>
<td><p>tlt-model-key=abc</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>segmentation-threshold</p></td>
<td><p>Confidence threshold for the segmentation model to output a valid class for a pixel. If confidence is less than this threshold, class output for that pixel is −1.</p></td>
<td><p>Float, ≥0.0</p></td>
<td><p>segmentation-threshold=0.3</p></td>
<td><p>Segmentation, Instance segmentation</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>segmentation-output-order</p></td>
<td><p>Segmentation network output layer order</p></td>
<td><p>Integer
0: NCHW
1: NHWC</p></td>
<td><p>segmentation-output-order=1</p></td>
<td><p>Segmentation</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>workspace-size</p></td>
<td><p>Workspace size to be used by the engine, in MB</p></td>
<td><p>Integer, &gt;0</p></td>
<td><p>workspace-size=45</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>force-implicit-batch-dim</p></td>
<td><p>When a network supports both implicit batch dimension and full dimension, force the implicit batch dimension mode.</p></td>
<td><p>Boolean</p></td>
<td><p>force-implicit-batch-dim=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>engine-create-func-name</p></td>
<td><p>Name of the custom TensorRT CudaEngine creation function. Refer to the “Custom Model Implementation Interface” section for details</p></td>
<td><p>String</p></td>
<td><p>engine-create-func-name=</p>
<p>NvDsInferYoloCudaEngineGet</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>cluster-mode</p></td>
<td><p>Clustering algorithm to use. Refer to the next table for configuring the algorithm specific parameters. Refer <a class="reference internal" href="DS_plugin_gst-nvinfer.html#cluster-mode-info"><span class="std std-ref">Clustering algorithms supported by nvinfer</span></a> for more information</p></td>
<td><p>Integer
0: OpenCV groupRectangles()
1: DBSCAN
2: Non Maximum Suppression
3: DBSCAN + NMS Hybrid
4: No clustering</p></td>
<td><p>cluster-mode=2</p>
<p>cluster-mode=4 for instance segmentation</p>
</td>
<td><p>Detector</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>filter-out-class-ids</p></td>
<td><p>Filter out detected objects belonging to specified class-ids</p></td>
<td><p>Semicolon delimited integer array</p></td>
<td><p>filter-out-class-ids=1</p></td>
<td><p>2</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>scaling-filter</p></td>
<td><p>The filter to use for scaling frames / object crops to network resolution (ignored if input-tensor-meta enabled)</p></td>
<td><p>Integer, refer to enum NvBufSurfTransform_Inter in nvbufsurftransform.h for valid values</p></td>
<td><p>scaling-filter=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>scaling-compute-hw</p></td>
<td><p>Compute hardware to use for scaling frames / object crops to network resolution (ignored if input-tensor-meta enabled)</p></td>
<td><p>Integer
0: Platform default – GPU (dGPU), VIC (Jetson)
1: GPU
2: VIC (Jetson only)</p></td>
<td><p>scaling-compute-hw=2</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>output-io-formats</p></td>
<td><p>Specifies the data type and order for bound output layers. For layers not specified, defaults to FP32 and CHW</p></td>
<td><p>Semi-colon separated list of format.
&lt;output-layer1-name&gt;:&lt;data-type&gt;:&lt;order&gt;;&lt;output-layer2-name&gt;:&lt;data-type&gt;:&lt;order&gt;</p>
<p>data-type should be one of
[fp32, fp16, int32, int8]</p>
<p>order should be one of [chw, chw2, chw4, hwc8, chw16, chw32]</p>
</td>
<td><p>output-io-formats=</p>
<p>conv2d_bbox:fp32:chw;conv2d_cov/Sigmoid:fp32:chw</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Layer-device-precision</p></td>
<td><p>Specifies the device type and precision for any layer in the network</p></td>
<td><p>Semi-colon separated list of format.
&lt;layer1-name&gt;:&lt;precision&gt;:&lt;device-type&gt;;&lt;layer2-name&gt;:&lt;precision&gt;:&lt;device-type&gt;;</p>
<p>precision should be one of
[fp32, fp16, int8]</p>
<p>Device-type should be one of [gpu, dla]</p>
</td>
<td><p>layer-device-precision=</p>
<p>output_cov/Sigmoid:fp32:gpu;output_bbox/BiasAdd:fp32:gpu;</p>
</td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>network-input-order</p></td>
<td><p>Order of the network input layer (ignored if input-tensor-meta enabled)</p></td>
<td><p>Integer
0:NCHW
1:NHWC</p></td>
<td><p>network-input-order=1</p></td>
<td><p>All</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>classifier-type</p></td>
<td><p>Description of what the classifier does</p></td>
<td><p>String (alphanumeric, ‘-’ and ‘_’ allowed, no spaces)</p></td>
<td><p>classifier-type=vehicletype</p></td>
<td><p>Classifier</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>crop-objects-to-roi-boundary</p></td>
<td><p>Clip the object bounding boxes to fit within the specified ROI boundary.</p></td>
<td><p>Boolean</p></td>
<td><p>crop-objects-to-roi-boundary=1</p></td>
<td><p>Detector</p>
<p>Both</p>
</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="pst-scrollable-table-container"><table class="table" id="id3">
<caption><span class="caption-text">Gst-nvinfer Class-attributes Group Supported Keys</span><a class="headerlink" href="DS_plugin_gst-nvinfer.html#id3" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Type and Range</p></th>
<th class="head"><p>Example</p>
<p>Notes</p>
</th>
<th class="head"><p>(Primary/Secondary)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>threshold</p></td>
<td><p>Detection threshold</p></td>
<td><p>Float, ≥0</p></td>
<td><p>threshold=0.5</p></td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-odd"><td><p>pre-cluster-threshold</p></td>
<td><p>Detection threshold to be applied prior to clustering operation</p></td>
<td><p>Float, ≥0</p></td>
<td><p>pre-cluster-threshold=</p>
<p>0.5</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-even"><td><p>post-cluster-threshold</p></td>
<td><p>Detection threshold to be applied post clustering operation</p></td>
<td><p>Float, ≥0</p></td>
<td><p>post-cluster-threshold=</p>
<p>0.5</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-odd"><td><p>eps</p></td>
<td><p>Epsilon values for OpenCV grouprectangles() function and DBSCAN algorithm</p></td>
<td><p>Float, ≥0</p></td>
<td><p>eps=0.2</p></td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-even"><td><p>group-threshold</p></td>
<td><p>Threshold value for rectangle merging for OpenCV grouprectangles() function</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>group-threshold=1</p>
<p>0 disables the clustering functionality</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-odd"><td><p>minBoxes</p></td>
<td><p>Minimum number of points required to form a dense region for DBSCAN algorithm</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>minBoxes=1</p>
<p>0 disables the clustering functionality</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-even"><td><p>dbscan-min-score</p></td>
<td><p>Minimum sum of confidence of all the neighbors in a cluster for it to be considered a valid cluster.</p></td>
<td><p>Float, ≥0</p></td>
<td><p>dbscan-min-score=</p>
<p>0.7</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-odd"><td><p>nms-iou-threshold</p></td>
<td><p>Maximum IOU score between two proposals after which the proposal with the lower confidence will be rejected.</p></td>
<td><p>Float, ≥0</p></td>
<td><p>nms-iou-threshold=</p>
<p>0.2</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-even"><td><p>roi-top-offset</p></td>
<td><p>Offset of the RoI from the top of the frame. Only objects within the RoI are output.</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>roi-top-offset=</p>
<p>200</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-odd"><td><p>roi-bottom-offset</p></td>
<td><p>Offset of the RoI from the bottom of the frame. Only objects within the RoI are output.</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>roi-bottom-offset=</p>
<p>200</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-even"><td><p>detected-min-w</p></td>
<td><p>Minimum width in pixels of detected objects to be output by the GIE</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>detected-min-w=</p>
<p>64</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-odd"><td><p>detected-min-h</p></td>
<td><p>Minimum height in pixels of detected objects to be output by the GIE</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>detected-min-h=</p>
<p>64</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-even"><td><p>detected-max-w</p></td>
<td><p>Maximum width in pixels of detected objects to be output by the GIE</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>detected-max-w=200</p>
<p>0 disables the property</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-odd"><td><p>detected-max-h</p></td>
<td><p>Maximum height in pixels of detected objects to be output by the GIE</p></td>
<td><p>Integer, ≥0</p></td>
<td><p>detected-max-h=200</p>
<p>0 disables the property</p>
</td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
<tr class="row-even"><td><p>topk</p></td>
<td><p>Keep only top K objects with highest detection scores.</p></td>
<td><p>Integer, ≥0.
-1 to disable</p></td>
<td><p>topk=10</p></td>
<td><p>Object detector</p>
<p>Both</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>UFF model support is removed from TRT 10.3.</p>
</div>
</div></blockquote>
</section>
<section id="gst-properties">
<h2>Gst Properties<a class="headerlink" href="DS_plugin_gst-nvinfer.html#gst-properties" title="Link to this heading">#</a></h2>
<p>The values set through Gst properties override the values of properties in the configuration file. The application does this for certain properties that it needs to set programmatically.
The following table describes the Gst-nvinfer plugin’s Gst properties.</p>
<div class="pst-scrollable-table-container"><table class="table" id="id4">
<caption><span class="caption-text">Gst-nvinfer Gst Properties</span><a class="headerlink" href="DS_plugin_gst-nvinfer.html#id4" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Meaning</p></th>
<th class="head"><p>Type and Range</p></th>
<th class="head"><p>Example notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>config-file-path</p></td>
<td><p>Absolute pathname of configuration file for the Gst-nvinfer element</p></td>
<td><p>String</p></td>
<td><p>config-file-path=­config_infer_primary.txt</p></td>
</tr>
<tr class="row-odd"><td><p>process-mode</p></td>
<td><p>Infer Processing Mode
1=Primary Mode
2=Secondary Mode</p></td>
<td><p>Integer, 1 or 2</p></td>
<td><p>process-mode=1</p></td>
</tr>
<tr class="row-even"><td><p>unique-id</p></td>
<td><p>Unique ID identifying metadata generated by this GIE</p></td>
<td><p>Integer, | 0 to 4,294,967,295</p></td>
<td><p>unique-id=1</p></td>
</tr>
<tr class="row-odd"><td><p>infer-on-gie-id</p></td>
<td><p>See operate-on-gie-id in the configuration file table</p></td>
<td><p>Integer,
0 to 4,294,967,295</p></td>
<td><p>infer-on-gie-id=1</p></td>
</tr>
<tr class="row-even"><td><p>operate-on-class-ids</p></td>
<td><p>See operate-on-class-ids in the configuration file table</p></td>
<td><p>An array of colon- separated integers (class-ids)</p></td>
<td><p>operate-on-class-ids=1:2:4</p></td>
</tr>
<tr class="row-odd"><td><p>filter-out-class-ids</p></td>
<td><p>See filter-out-class-ids in the configuration file table</p></td>
<td><p>Semicolon delimited integer array</p></td>
<td><p>filter-out-class-ids=1;2</p></td>
</tr>
<tr class="row-even"><td><p>model-engine-file</p></td>
<td><p>Absolute pathname of the pre-generated serialized engine file for the mode</p></td>
<td><p>String</p></td>
<td><p>model-engine-file=­model_b1_fp32.engine</p></td>
</tr>
<tr class="row-odd"><td><p>batch-size</p></td>
<td><p>Number of frames/objects to be inferred together in a batch</p></td>
<td><p>Integer,
1 – 4,294,967,295</p></td>
<td><p>batch-size=4</p></td>
</tr>
<tr class="row-even"><td><p>Interval</p></td>
<td><p>Number of consecutive batches to be skipped for inference</p></td>
<td><p>Integer, 0 to 32</p></td>
<td><p>interval=0</p></td>
</tr>
<tr class="row-odd"><td><p>gpu-id</p></td>
<td><p>Device ID of GPU to use for pre-processing/inference (dGPU only)</p></td>
<td><p>Integer,
0-4,294,967,295</p></td>
<td><p>gpu-id=1</p></td>
</tr>
<tr class="row-even"><td><p>raw-output-file-write</p></td>
<td><p>Pathname of raw inference output file</p></td>
<td><p>Boolean</p></td>
<td><p>raw-output-file-write=1</p></td>
</tr>
<tr class="row-odd"><td><p>raw-output-generated-callback</p></td>
<td><p>Pointer to the raw output generated callback function</p></td>
<td><p>Pointer</p></td>
<td><p>Cannot be set through gst-launch</p></td>
</tr>
<tr class="row-even"><td><p>raw-output-generated-userdata</p></td>
<td><p>Pointer to user data to be supplied with raw-output-generated-callback</p></td>
<td><p>Pointer</p></td>
<td><p>Cannot be set through gst-launch</p></td>
</tr>
<tr class="row-odd"><td><p>output-tensor-meta</p></td>
<td><p>Indicates whether to attach tensor outputs as meta on GstBuffer.</p></td>
<td><p>Boolean</p></td>
<td><p>output-tensor-meta=0</p></td>
</tr>
<tr class="row-even"><td><p>output-instance-mask</p></td>
<td><p>Gst-nvinfer attaches instance mask output in object metadata.</p></td>
<td><p>Boolean</p></td>
<td><p>output-instance-mask=1</p></td>
</tr>
<tr class="row-odd"><td><p>input-tensor-meta</p></td>
<td><p>Use preprocessed input tensors attached as metadata instead of preprocessing inside the plugin</p></td>
<td><p>Boolean</p></td>
<td><p>input-tensor-meta=1</p></td>
</tr>
<tr class="row-even"><td><p>crop-objects-to-roi-boundary</p></td>
<td><p>Clip the object bounding boxes to fit within the specified ROI boundary</p></td>
<td><p>Boolean</p></td>
<td><p>crop-objects-to-roi-boundary=1</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="clustering-algorithms-supported-by-nvinfer">
<span id="cluster-mode-info"></span><h2>Clustering algorithms supported by nvinfer<a class="headerlink" href="DS_plugin_gst-nvinfer.html#clustering-algorithms-supported-by-nvinfer" title="Link to this heading">#</a></h2>
<section id="cluster-mode-0-grouprectangles">
<h3>cluster-mode = 0 | GroupRectangles<a class="headerlink" href="DS_plugin_gst-nvinfer.html#cluster-mode-0-grouprectangles" title="Link to this heading">#</a></h3>
<p>GroupRectangles is a clustering algorithm from OpenCV library which clusters rectangles of similar size and location using the rectangle equivalence criteria. Link to API documentation - <a class="reference external" href="https://docs.opencv.org/3.4/d5/d54/group__objdetect.html#ga3dba897ade8aa8227edda66508e16ab9">https://docs.opencv.org/3.4/d5/d54/group__objdetect.html#ga3dba897ade8aa8227edda66508e16ab9</a></p>
</section>
<section id="cluster-mode-1-dbscan">
<h3>cluster-mode = 1 | DBSCAN<a class="headerlink" href="DS_plugin_gst-nvinfer.html#cluster-mode-1-dbscan" title="Link to this heading">#</a></h3>
<p>Density-based spatial clustering of applications with noise or DBSCAN is a clustering algorithm which which identifies clusters by checking if a specific rectangle has a minimum number of neighbors in its vicinity defined by the eps value. The algorithm further normalizes each valid cluster to a single rectangle which is outputted as valid bounding box if it has a confidence greater than that of the threshold.</p>
</section>
<section id="cluster-mode-2-nms">
<h3>cluster-mode = 2 | NMS<a class="headerlink" href="DS_plugin_gst-nvinfer.html#cluster-mode-2-nms" title="Link to this heading">#</a></h3>
<p>Non maximum suppression or NMS is a clustering algorithm which filters overlapping rectangles based on a degree of overlap(IOU) which is used as threshold. Rectangles with the highest confidence score is first preserved while the rectangles which overlap greater than the threshold are removed iteratively.</p>
</section>
<section id="cluster-mode-3-hybrid">
<h3>cluster-mode = 3 | Hybrid<a class="headerlink" href="DS_plugin_gst-nvinfer.html#cluster-mode-3-hybrid" title="Link to this heading">#</a></h3>
<p>Hybrid clustering algorithm is a method which uses both DBSCAN and NMS algorithms in a two step process. DBSCAN is first applied to form unnormalized clusters in proposals whilst removing the outliers. NMS is later applied on these clusters to select the final rectangles for output.</p>
</section>
<section id="cluster-mode-4-no-clustering">
<h3>cluster-mode=4 | No clustering<a class="headerlink" href="DS_plugin_gst-nvinfer.html#cluster-mode-4-no-clustering" title="Link to this heading">#</a></h3>
<p>No clustering is applied and all the bounding box rectangle proposals are returned as it is.</p>
</section>
</section>
<section id="tensor-metadata">
<h2>Tensor Metadata<a class="headerlink" href="DS_plugin_gst-nvinfer.html#tensor-metadata" title="Link to this heading">#</a></h2>
<p>The Gst-nvinfer plugin can attach raw output tensor data generated by a TensorRT inference engine as metadata. It is added as an <cite>NvDsInferTensorMeta</cite> in the <code class="docutils literal notranslate"><span class="pre">frame_user_meta_list</span></code> member of <cite>NvDsFrameMeta</cite> for primary (full frame) mode, or in the <code class="docutils literal notranslate"><span class="pre">obj_user_meta_list</span></code> member of <cite>NvDsObjectMeta</cite> for secondary (object) mode.</p>
<section id="to-read-or-parse-inference-raw-tensor-data-of-output-layers">
<h3>To read or parse inference raw tensor data of output layers<a class="headerlink" href="DS_plugin_gst-nvinfer.html#to-read-or-parse-inference-raw-tensor-data-of-output-layers" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Enable property <cite>output-tensor-meta</cite> or enable the same-named attribute in the configuration file for the Gst-nvinfer plugin.</p></li>
<li><p>When operating as primary GIE,` NvDsInferTensorMeta` is attached to each frame’s (each <cite>NvDsFrameMeta</cite> object’s) <code class="docutils literal notranslate"><span class="pre">frame_user_meta_list</span></code>. When operating as secondary GIE, <cite>NvDsInferTensorMeta</cite> is attached to each each <cite>NvDsObjectMeta</cite> object’s <code class="docutils literal notranslate"><span class="pre">obj_user_meta_list</span></code>.</p></li>
</ol>
<blockquote>
<div><p>Metadata attached by Gst-nvinfer can be accessed in a GStreamer pad probe attached downstream from the Gst-nvinfer instance.</p>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>The <cite>NvDsInferTensorMeta</cite> object’s metadata type is set to <code class="docutils literal notranslate"><span class="pre">NVDSINFER_TENSOR_OUTPUT_META</span></code>. To get this metadata you must iterate over the <cite>NvDsUserMeta</cite> user metadata objects in the list referenced by <code class="docutils literal notranslate"><span class="pre">frame_user_meta_list</span></code> or <code class="docutils literal notranslate"><span class="pre">obj_user_meta_list</span></code>.</p></li>
</ol>
<p>For more information about Gst-infer tensor metadata usage, see the source code in <code class="docutils literal notranslate"><span class="pre">sources/apps/sample_apps/deepstream_infer_tensor_meta-test.cpp</span></code>, provided in the DeepStream SDK samples.</p>
</section>
</section>
<section id="segmentation-metadata">
<h2>Segmentation Metadata<a class="headerlink" href="DS_plugin_gst-nvinfer.html#segmentation-metadata" title="Link to this heading">#</a></h2>
<p>The Gst-nvinfer plugin attaches the output of the segmentation model as user meta in an instance of <code class="docutils literal notranslate"><span class="pre">NvDsInferSegmentationMeta</span></code> with meta_type set to <code class="docutils literal notranslate"><span class="pre">NVDSINFER_SEGMENTATION_META</span></code>. The user meta is added to the <code class="docutils literal notranslate"><span class="pre">frame_user_meta_list</span></code> member of <code class="docutils literal notranslate"><span class="pre">NvDsFrameMeta</span></code> for primary (full frame) mode, or the <code class="docutils literal notranslate"><span class="pre">obj_user_meta_list</span></code> member of <code class="docutils literal notranslate"><span class="pre">NvDsObjectMeta</span></code> for secondary (object) mode.
For guidance on how to access user metadata, see <a class="reference internal" href="DS_plugin_metadata.html#user-custom-metadata-label"><span class="std std-ref">User/Custom Metadata Addition inside NvDsBatchMeta</span></a> and <a class="reference internal" href="DS_plugin_gst-nvinfer.html#tensor-metadata">Tensor Metadata</a> sections.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="DS_plugin_gst-nvdspreprocess.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Gst-nvdspreprocess (Alpha)</p>
      </div>
    </a>
    <a class="right-next"
       href="DS_plugin_gst-nvinferserver.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Gst-nvinferserver</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#inputs-and-outputs">Inputs and Outputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#features">Features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#gst-nvinfer-file-configuration-specifications">Gst-nvinfer File Configuration Specifications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#gst-properties">Gst Properties</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#clustering-algorithms-supported-by-nvinfer">Clustering algorithms supported by nvinfer</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#cluster-mode-0-grouprectangles">cluster-mode = 0 | GroupRectangles</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#cluster-mode-1-dbscan">cluster-mode = 1 | DBSCAN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#cluster-mode-2-nms">cluster-mode = 2 | NMS</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#cluster-mode-3-hybrid">cluster-mode = 3 | Hybrid</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#cluster-mode-4-no-clustering">cluster-mode=4 | No clustering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#tensor-metadata">Tensor Metadata</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#to-read-or-parse-inference-raw-tensor-data-of-output-layers">To read or parse inference raw tensor data of output layers</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="DS_plugin_gst-nvinfer.html#segmentation-metadata">Segmentation Metadata</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js%3Fdigest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js%3Fdigest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
<a class="footer-brand logo" href="https://www.nvidia.com">
  <img src="../_static/nvidia-logo-horiz-rgb-1c-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA"/>
  <img src="../_static/nvidia-logo-horiz-rgb-1c-wht-for-screen.svg" class="logo__image only-dark" alt="NVIDIA"/>
</a></div>
      
        <div class="footer-item">

<div class="footer-links">
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/">Privacy Policy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/">Manage My Privacy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/preferences/start/">Do Not Sell or Share My Data</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/">Terms of Service</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/accessibility/">Accessibility</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/company-policies/">Corporate Policies</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/product-security/">Product Security</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/contact/">Contact</a>
  
  
  
</div>
</div>
      
        <div class="footer-item">



  <p class="copyright">
    
      Copyright © 2024-2025, NVIDIA Corporation.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item"><p class="last-updated">
  Last updated on Sep 15, 2025.
  <br/>
</p></div>
      
        <div class="footer-item">
<div class="extra_footer">
  
      <script type="text/javascript">if (typeof _satellite !== "undefined") {_satellite.pageBottom();}</script>
    
  
</div></div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>